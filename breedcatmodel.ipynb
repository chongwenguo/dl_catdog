{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import numpy as np\n",
    "import torchvision.models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_val(datadir, valid_size = .25):\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "    train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "    val_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      normalize\n",
    "                                      ])\n",
    "    train_data = torchvision.datasets.ImageFolder(datadir,\n",
    "                    transform=train_transforms)\n",
    "    val_data = torchvision.datasets.ImageFolder(datadir,\n",
    "                    transform=val_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    classes = train_data.classes\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=1)\n",
    "    valloader = torch.utils.data.DataLoader(val_data,\n",
    "                   sampler=val_sampler, batch_size=1)\n",
    "    dataiter = iter(trainloader) \n",
    "    images, labels = dataiter.next()\n",
    "    return trainloader, valloader, classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    #train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            i = 0\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "                dataloader = trainloader\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valloader\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloader:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                \n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "                #print (str(i) + \":\" + str(running_loss) + \":\" + str(running_corrects))\n",
    "                #i += 1\n",
    "                \n",
    "                #train_losses.append(running_loss/len(trainloader))\n",
    "                #test_losses.append(test_loss/len(testloader)) \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model#, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/masked_images/data/trainval/breeds_cat/'\n",
    "trainloader, valloader, classes, labels = load_split_train_val(data_dir, .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    \"train\": len(trainloader),\n",
    "    \"val\": len(valloader)\n",
    "}\n",
    "\n",
    "# use gpu or not\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "model_cat = torchvision.models.resnet50(pretrained=True)\n",
    "#model_cat = torchvision.models.vgg16(pretrained=True)s\n",
    "num_ftrs = model_cat.fc.in_features\n",
    "#model_cat.classifier[-1] = nn.Linear(in_features=4096, out_features=12)\n",
    "\n",
    "model_cat.fc = nn.Linear(num_ftrs, 12)\n",
    "\n",
    "if use_gpu:\n",
    "    model_cat = model_cat.cuda()\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_cat.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 2.5813 Acc: 0.0839\n",
      "val Loss: 2.5337 Acc: 0.1342\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.5726 Acc: 0.0846\n",
      "val Loss: 2.4265 Acc: 0.1405\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 2.5520 Acc: 0.0964\n",
      "val Loss: 2.3451 Acc: 0.1426\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 2.5368 Acc: 0.0936\n",
      "val Loss: 2.2183 Acc: 0.1950\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 2.4951 Acc: 0.1034\n",
      "val Loss: 2.1274 Acc: 0.3375\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 2.3836 Acc: 0.1516\n",
      "val Loss: 1.9724 Acc: 0.3878\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 2.2519 Acc: 0.1775\n",
      "val Loss: 1.8092 Acc: 0.3753\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 2.0518 Acc: 0.3249\n",
      "val Loss: 1.6988 Acc: 0.5388\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 2.0110 Acc: 0.4116\n",
      "val Loss: 1.6851 Acc: 0.5430\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.9882 Acc: 0.4088\n",
      "val Loss: 1.7171 Acc: 0.5241\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.9654 Acc: 0.4067\n",
      "val Loss: 1.5770 Acc: 0.4864\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4095\n",
      "val Loss: 1.5772 Acc: 0.5891\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.9191 Acc: 0.4361\n",
      "val Loss: 1.5840 Acc: 0.5723\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.8987 Acc: 0.4242\n",
      "val Loss: 1.5823 Acc: 0.4948\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.8693 Acc: 0.4396\n",
      "val Loss: 1.5703 Acc: 0.4822\n",
      "Training complete in 25m 14s\n",
      "Best val Acc: 0.589099\n"
     ]
    }
   ],
   "source": [
    "model_cat = train_model(model=model_cat,\n",
    "                           criterion=criterion,\n",
    "                           optimizer=optimizer_ft,\n",
    "                           scheduler=exp_lr_scheduler,\n",
    "                           num_epochs=15)\n",
    "torch.save(model_cat, './resnet50_breed_cat.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'data/masked_images/data/test/breeds_cat/'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=torch.load('resnet50_breed_cat.pth')\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(test_data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, \n",
    "                   sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels, classes = get_random_images(5)\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(classes[index]) + \":\" + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy for all breeds 46% \n",
      "\n",
      "Accuracy of Abyssinian : 52 %\n",
      "Accuracy of Bengal :  5 %\n",
      "Accuracy of Birman : 47 %\n",
      "Accuracy of Bombay : 46 %\n",
      "Accuracy of British_Shorthair : 75 %\n",
      "Accuracy of Egyptian_Mau :  0 %\n",
      "Accuracy of Maine_Coon : 87 %\n",
      "Accuracy of Persian : 67 %\n",
      "Accuracy of Ragdoll : 10 %\n",
      "Accuracy of Russian_Blue :  0 %\n",
      "Accuracy of Siamese : 75 %\n",
      "Accuracy of Sphynx : 82 %\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "test_transforms1 = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                        normalize\n",
    "                                     ])\n",
    "test_data = torchvision.datasets.ImageFolder(test_data_dir,\n",
    "                    transform=test_transforms1)\n",
    "testloader = torch.utils.data.DataLoader(test_data,\n",
    "                 batch_size=1)\n",
    "total_images = 0\n",
    "total_correct = 0\n",
    "class_correct = list(0. for i in range(12))\n",
    "class_total = list(0. for i in range(12))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if use_gpu:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images, labels = Variable(inputs), Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        label = labels[0]\n",
    "        class_correct[label] += c.item()\n",
    "        class_total[label] += 1\n",
    "        total_images += 1\n",
    "        total_correct += c.item()\n",
    "print('Overall accuracy for all breeds %2d%% ' % (\n",
    "            100 * total_correct / total_images))\n",
    "print() \n",
    "for i in range(12):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            \n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
