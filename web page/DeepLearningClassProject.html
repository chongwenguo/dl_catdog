<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Deep Learning Class Project
    | Georgia Tech | Spring 2019: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
  <style>
    body {
      padding-top: 60px;
      /* 60px to make the container go all the way to the bottom of the topbar */
    }

    .vis {
      color: #3366CC;
    }

    .data {
      color: #FF9900;
    }
  </style>

  <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
  <div class="container">
    <div class="page-header">

      <!-- Title and Name -->
      <h1>Cats and Dogs Breed Classification</h1>
      <span style="font-size: 20px; line-height: 1.5em;"><strong>Chongwen Guo, Zhuoran Yu</strong></span><br>
      <span style="font-size: 18px; line-height: 1.5em;">Spring 2019 CS 4803 / 7643 Deep Learning: Class
        Project</span><br>
      <span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
      <hr>

      <!-- Goal -->
      <!-- <h2>Abstract</h2>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br> -->
      <!-- figure -->
      <!-- <h2>Teaser figure</h2>
A figure that conveys the main idea behind the project or the main application being addressed. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)
<br><br> -->
      <!-- Main Illustrative Figure -->
      <!-- <div style="text-align: center;">
<img style="height: 200px;" alt="" src="images/alexnet.png">
</div> -->
      <div style="text-align: center;">
        <img style="height: 230px;" alt="" src="images/sample-dataset.jpg">
        <br>Figure 1. The Oxford-IIIT Pet Dataset
      </div>
      <br>
      <!-- Introduction -->
      <h2>Introduction / Background / Motivation</h2>

      <h4>Introduction</h4>
      This project aims to examine whether modern computer vision techniques work well in classification problems where
      different classes of images have relatively high similarities. The dataset we chose for this project is
      the Oxford-IIIT Pet Dataset published by VGG group.
      We are interested in three classification problems: binary classification of cats and dogs, cat breeds
      classification,
      and dog breeds classification.
      The project consists of three major stages: build models from scratch, fine-tune pre-trained models and data
      augmentation with GAN.
      The Oxford-IIIT Pet Dataset contains 37 categories of pets with roughly 200 images for each class. The images have
      a large variations in scale, pose and lighting. Due to high inter class variability, low intra class variability
      and high pose variability, it is not easy to train and obtain a high accarucy breed-classifier, especially when
      the data volume is limited.
      We would like to use GAN to generate several fake cats and dog images. With generated images, we would like
      to see if they can improve accuracy of classifiers if used as data augmentation and if the classifier can
      correctly classify them.
      <br><br>

      <h4>Motivation</h4>
      Image Classification is one of the most common task in computer vision which are well-studied over past few years.
      Model architectures have been improved from basic convolutional neural networks to some more complex models such
      as
      ResNet, Inception, etc. However, majority of these models are tested in common classification tasks such as
      ImageNet,
      where most classes expose a relatively low similarity to each other. Therefore, we are interested in whether
      modern
      computer vision models have enough power to do classification problems like this.
      Another motivation is the limitation of data. People usually claim that for complex image classfication problems,
      at least 1000 images per class are necessary. In our dataset, each breed only has approximately 200 samples, which
      are
      far more from this widely accepted requirement. We are then interested in how well classifiers can do when images
      are not
      sufficient and whether data augmentation techniques could improve the performance of our models.
      <br><br>
      <br><br><br>
      <div class="container" style='display: flex;'>

        <div style='flex: 1;text-align: center'>
          <img style="height: 380px;" alt="" src="images/breed_count.jpg">
          <br>Figure 2: Dataset Statistics
        </div>
        <div style='flex: 1;text-align: left'>
          <img style="height: 120px;" alt="" src="images/low-inter-class-variability.jpg">
          <br>Figure 3: Example of high intra class variability with two American Pit Bull Terriers and two Maine coons

          <br><img style="height: 100px;" alt="" src="images/high-intra-class-variability.jpg">
          <br>Figure 4: Example of low inter class variability with Beagle, Saint Bernard and British Shorthair,
          Russian Blue
          <br><img style="height: 120px;" alt="" src="images/high-pose-variability.jpg">
          <br>Figure 5: Example of high pose variability with four members of Miniature Pinschers
        </div>

      </div>

      <h4>Backgrounds and Related Works</h4>

      For this dataset specifically, fine-grained recognition works has been demonstrated on cats and dogs by
      O. M. Parkhi, A. Vedaldi, A. Zisserman and C. V. Jawahar, which trained 63.48% and 55.68% accuracy breed
      classification
      for cats and dogs respectively, which improved to 66.07% and 59.18% when the ground truth segmentations are used.
      We are using these models as our baselines. We are looking forward to check if we can build a model from scratch
      with potential data
      augmentation techniques to beat them.

      <br><br>
      <!-- Approach -->
      <h2>Approach</h2>

      The project has two main stages: building models and implementing data augmentation.
      First, the first model we want to try is to fine-tuning some famous pre-trained models. We want to see if this
      approach can give
      any promising results in our task. If so, this fine-tining model is used as our new baseline.
      Second, we are building models from scratch to see if we can beat baselines(either fine-tuning models or models
      mentioned in background
      section). Even though there are various large famous architectures in community such as ResNet and GoogleNet, they
      are too big to be fit
      in our small GPUs. We are trying to build our customized models with some ideas borrowed from those famous
      architectures but not using their
      exact models.
      Once we have such a model, we will include data augmentation in our training process. We'll start with some
      standard operations and see if
      performance can be improved. Then, we will implement data augmentation by GAN, which is more complex than simpple
      image operations.
      <br><br>
      <h4>Baseline Models</h4>
      We have chosen two baseline models for experiments and both
      are variations of Resnets because Resnets is one of the
      state-of-the-art model.
      The first one is a fine-tuning model of Resnet-50. We loaded
      pretrained weights of Resnet-50 from PyTorch and Fine-tuned it
      on our datasets.
      The second one is Resnet-18 without pretrained weights. We are
      trying to see if our model can show some competitive behavior
      with it.

      <br><br>
      <h4> Model Built From Scratch </h4>
      We built a model from scratch to do the classification task. There are
      already many state-of-the-art models. However, most of them have
      such large sizes that cannot fit in our machine such as GoogleNet.
      Therefore, we are aiming to build a smaller model that combines
      stengths of those state-of-the-art models.
      InceptionR and InceptionD are both customized inception blocks.
      <br><br>
      <h4> Customized Inceptions </h4>
      Since we have limited computing power, the idea of inceptionR is
      to include as many different filters as possible without changing
      the output size.
      Similarly, inceptionD would also include more filters than original
      inception blocks and the size of output is halved.
      InceptionR is shown below

      <br><br>
      <div class="container" style='display: flex;'>

        <div style='flex: 1;text-align: center'>
          <br><br><br><br>
          <img style="height: 120px;" alt="" src="images/model_table.png">
        </div>
        <div style='flex: 1;text-align: left'>
          <img style="height: 300px;" alt="" src="images/model_scratch.png">
          <br>
        </div>
      </div>
      <br>
      <p align="center">Figure 6: Model Structures</p>

      <br><br>
      <!-- Results -->
      <h2>Experimentals and Results</h2>

      Our experimental plan follows our plan of attack. There are three main tasks we need to experiment: dog-cat binary
      classification, cat breeds classificaion and dog breeds classification. For each of them, our experiments are
      organized as follows:
      Two main models are used: the model we build from scratch and fine-tuning models.
      For fine-tuning models, we pick ResNet-50 because of it's promising performance on other tasks and the size of its
      model.
      For each model, we also experiment it with different data augmentaiton techniques, namely, no augmentation
      included, one or two standard data
      augmentation approach, and one data augmentation technique by GAN.

      We are curious to see whether we can build a model to beat baselines and how much the model performance can be
      improved by data augmentation.

      <br><br>
      <h4> Data Augmentation by GAN</h4>
      Generative Adversarial Network is one of the most interesting
      work in deep learning recently. It has various applications in
      different areas of deep learning, data augmentation is one of
      them.
      Steps:
      <br>1. Generate fake images
      <br>2. Solving label issues: human labor, average weights, new
      label, etc

      <h4>GAN Failure Cases</h4>
      In general, even to generate greyscaled images, GAN would
      require a large dimension in hidden layers, which exceeds our
      memory limits. Our images are RGB images with size around
      200 x 200, which requires more computation resources.
      We built a GAN with significantly smaller size and present failure
      case here.
      <br><br>
      <div class="container" style='display: flex;'>

        <div style='flex: 1;text-align: center'>
          <img style="height: 380px;" alt="" src="images/generator_loss.png">

        </div>
        <div style='flex: 1;text-align: left'>
          <img style="height: 380px;" alt="" src="images/discriminator_loss.png">
          <br>

        </div>

      </div>
      <br>

      <br>
      Losses indicate that generator almost gives up on “fooling”
      discriminator and the discriminator fails to give convincing
      predictions.
      This is because of the small size of generator and discriminator:
      generator cannot generate “interesting” outputs and the
      prediction power of discriminator is also limited.
      <br><br>

      <h4> Model Accuracies</h4>

      <br>For cat-dog binary classifier, we are able to built model from scratch with 86% overall accuracy.
      <br><br>
      <div style='flex: 1;text-align: center'>
        <img style="height: 200px;" alt="" src="images/cat_dog_binary.png">
      </div>

      <br>The graph shown below summarizes the accuracies for resnet 50
      dog-breed classifier.
      <div style='flex: 1;text-align: center'>
        <br><img style="height: 320px;" alt="" src="images/res50_dog.png">

      </div>

      <br>The table below summarizes the accuracies for cat-breed
      classifier models we currently achieved.
      <br><br>
      <div style='flex: 1;text-align: center'>
        <img style="height: 150px;" alt="" src="images/cat_result_table.png">

      </div>
      <br>
      By using the grab-cut segmentation technique, which uses a SVM classifier to assign superpixels a confidence score
      and then to label of foreground or background region, masked images that only contains animal body are created.
      This improves the accuracy for the model from scratch from 37% to 55%.
      <div class="container" style='display: flex;'>

        <div style='flex: 1;text-align: center'>
          <br><img style="height: 250px;" alt="" src="images/masked_images.png">
        </div>
        <div style='flex: 1;text-align: left'>
          <br><img style="height: 250px;" alt="" src="images/cat_strach_improved.png">
          <br>
        </div>
      </div>
      <br>
    </div>
    <!-- Analysis -->
    <h2>Analysis and Conclusion</h2>
    Both our model and Resnet 18 trained from scratch cannot
    beat resnet-50 fine-tuned model.
    We only have 200 images for each class, which is far from
    the number of image required for normal classification tasks
    where DL models succeed(usually ~1000 per class)
    Fine-tuning models provide a way better initial weights for
    classification problems when dataset is not huge.

    1. When dataset size is not huge, deep learning models do not
    have significant advantages over SVM.
    <br>2. When dataset size is not huge, training from scratch does not
    give better performance than fine-tuning.
    <br>3. Using GAN for complicated images require intensive
    computational resources.
    <br><br>
    <h2>Team Member Identification</h2>
    <!-- Team -->
    <table style="width:100%">
      <tr>
        <th>Name</th>
        <th>Description of Work</th>
      </tr>
      <tr>
        <td>Chongwen Guo</td>
        <td>Data preprocessing and model utils functions, tuned hyper-parameters for Pretrained ResNet-50
          convolutional neural network
          <br></td>
      </tr>
      <tr>
        <td>Zhuoran Yu</td>
        <td>build models from scratch, perform traditional data augmentation and data augmentation with GAN</td>
      </tr>
    </table>
    <br>

  </div>
  </div>
</body>

</html>